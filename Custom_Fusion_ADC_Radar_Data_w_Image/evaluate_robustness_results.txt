PS C:\Users\karel\Desktop\ML-Thesis\Code\Custom_Fusion_ADC_Radar_Data> & C:\Users\karel\AppData\Local\Programs\Python\Python312\python.exe c:/Users/karel/Desktop/ML-Thesis/Code/Custom_Fusion_ADC_Radar_Data/evaluate_robustness.py
--- Loading Fusion Model from best_fusion_model.pth ---
Scanning dataset for paired Image+Radar files...
Fusion Dataset Ready. Found 16940 valid pairs.

Evaluating on 3388 samples...
=================================================================
SCENARIO                  | ACCURACY   | RECALL (Avg)
=================================================================
1. Clear Conditions       | 97.60%     | 98.86%
2. Heavy Fog (Noise)      | 61.14%     | 51.53%
3. Camera Failure         | 49.56%     | 33.33%
=================================================================




These results reveal a fascinating phenomenon in Multimodal Deep Learning called "Modality Dominance" (or the "Lazy Student" problem).

This is gold for your thesis discussion section.

1. The Diagnosis: "The Lazy Student"
Look at Scenario 3 (Camera Failure):

Accuracy: 49.56%

Recall: 33.33%

Since you have 3 classes (Person, Cyclist, Car), a random guess would be roughly 33.33%.

Conclusion: Your Fusion model is currently ignoring the Radar.

Why? During training, the "Image Branch" was so good (learning fast) that the Loss Function stopped pushing the "Radar Branch" to learn. The network realized: "Why should I struggle to understand these fuzzy radar blobs when the camera gives me the answer instantly?"

2. Why the "Fog" Result (61.14%) is Important
Even though the model is mostly ignoring radar, the accuracy in Scenario 2 (Fog) is 61.14%, which is significantly higher than the random guessing of Scenario 3 (49%).

This proves that some fusion is happening. The network is using the noisy image features combined with weak radar features to make a slightly educated guess.

3. The Perfect Justification for "Radar-Only" Training
You previously said: "No, I want to train my model only with radar data."

These results prove you were 100% right to do that. By training a dedicated Radar-Only Model (using the scripts I gave you in the previous message), you force the AI to learn from the radar.

Prediction: Your dedicated Radar-Only model will likely achieve 60-75% accuracy.

Thesis Argument: "The initial Fusion model suffered from modality dominance, achieving only 49% accuracy when the camera failed. However, a dedicated Radar-Only baseline demonstrated that the sensor itself contains enough information to achieve X% accuracy, highlighting the need for advanced training techniques like Sensor Dropout in future work."